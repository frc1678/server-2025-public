#!/usr/bin/env python3

"""Holds variables + functions that are shared across server files."""

import inspect
import os
from pathlib import Path
import shlex
import subprocess
import sys
import traceback
import csv
from math import isclose
from typing import Dict, Literal, List, Any
import logging
from typing import Union
from console import console
import builtins
import json
import pandas as pd
import pprint

MAIN_DIRECTORY = Path(os.path.abspath(__file__)).parents[1]
log = logging.getLogger(__name__)

try:
    import yaml
except ImportError:
    log.error("PyYaml not found, load schema is unavailable", file=sys.stderr)


def create_file_path(path_after_main, create_directories=True) -> str:
    """Joins the path of the directory this script is in with the path that is passed

    to this function. path_after_main is the path from inside the main directory.
    For example, the path_after_main for server.py would be 'server.py' because it is located
    directly in the main directory. create_directories will create the directories in the path if
    they do not exist. Assumes that all files names include a period, and all paths are input in
    Linux/Unix style. create_directories defaults to True.
    """
    # Removes trailing slash in 'path_after_main' (if it exists) and split by '/'
    path_after_main = path_after_main.rstrip("/").split("/")
    if create_directories is True:
        # Checks if the last item in the path is a file
        if "." in path_after_main[-1]:
            # Only try to create directories if there are directories specified before filename
            if len(path_after_main) > 1:
                # The '*' before the variable name expands the list into arguments for the function
                directories = os.path.join(*path_after_main[:-1])
            # Make directories a blank string
            else:
                directories = ""
        # The last item is a directory
        else:
            directories = os.path.join(*path_after_main)
        # 'os.makedirs' recursively creates directories; it creates multiple directories if needed
        os.makedirs(os.path.join(MAIN_DIRECTORY, directories), exist_ok=True)
    return os.path.join(MAIN_DIRECTORY, *path_after_main)


def get_bool(value: str) -> bool:
    """Get boolean from string."""
    if value.upper() in ["1", "T", "TRUE"]:
        return True
    if value.upper() in ["0", "F", "FALSE"]:
        return False
    raise ValueError(f"Unable to convert {value} to boolean.")


def catch_function_errors(fn, *args, **kwargs):
    """Returns function return value or None if there are errors."""
    try:
        result = fn(*args, **kwargs)
    # Keyboard interrupts should stop server
    except KeyboardInterrupt:
        raise
    # Notify user that error occurred
    except Exception as err:
        log.error(f"Caught a function error: {err}")
        result = None
    return result


def run_command(command, return_output=False):
    """Runs a command using subprocess.

    command (string) is the terminal command to be run returns the standard output of the command
    if return_output is True.
    """
    # Use shlex.split to preserve spaces within quotes and preserve the quotes
    command = shlex.split(command, posix=False)
    try:
        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            delim = f"\n{'-'*20}\n"
            raise Exception(
                delim.join(
                    [
                        f'utils.run_command: error in command "{" ".join(command)}"',
                        "Captured stdout:",
                        result.stdout.decode("utf-8"),
                        "Captured stderr:",
                        result.stderr.decode("utf-8"),
                    ]
                )
            )
        return result.stdout.decode("utf-8").replace("\r\n", "\n") if return_output else None
    except FileNotFoundError:
        raise Exception(f"utils.run_command: unknown command {command[0]}")


def _inner_read_schema(schema_file_path: str) -> dict:
    """Reads schema files and returns them as a dictionary.

    schema_filepath is the relative file path compared to where the script is executed
    returns a dictionary generated by opening the schema document with yaml.
    """

    # Opens the schema file and returns it as a dictionary
    try:
        with open(create_file_path(schema_file_path, False), "r") as schema_file:
            # Specify loader to avoid warnings about default loader
            return yaml.load(schema_file, yaml.Loader)
    except FileNotFoundError as e:
        # TODO - use logging (waiting on #544 for better logging)
        log.error(f'file "{schema_file_path}" not found.')
        log.info(f"server: full info: {e}")
        # Please check for None
        return None


_internal_schemas = {}


def read_schema(schema_file_path: str) -> dict:
    if schema_file_path not in _internal_schemas.keys():
        _internal_schemas[schema_file_path] = _inner_read_schema(schema_file_path)
    return _internal_schemas[schema_file_path]


def get_schema_filenames() -> list:
    """Get all the file names of schema files from the collection_schema"""
    schema = read_schema("schema/collection_schema.yml")
    schema_filenames = []
    for schema in schema["collections"].values():
        schema_filename = schema["schema"]
        if schema_filename is not None:
            schema_filenames.append(schema_filename)
    return schema_filenames


# The root directory of the project
# Gets two directories up from the current file
MAIN_DIRECTORY = Path(os.path.abspath(__file__)).parents[1]


def load_tba_event_key_file(file_path):
    try:
        # Specifies which event - string such as '2020cada'.
        with open(create_file_path(file_path)) as file:
            # Remove trailing newline (if it exists) from file data.
            # Many file editors will automatically add a newline at the end of files.
            return file.read().rstrip("\n")
    except FileNotFoundError:
        log.warning(f"ERROR Loading TBA Key: File {file_path} NOT FOUND")
        return None


def unprefix_schema_dict(schema_in):
    """Turn a.b.c into just c for every key in a nested schema dictionary - iterate through all
    keys and turn each one from foo.bar to just bar, and apply recursively if any of the values are
    dictionaries themselves."""
    schema_out = {}
    keys = list(schema_in.keys())
    for key in keys:
        stripped_key = key.split(".")[-1]  # Turn a.b.c.d.e into e
        schema_out[stripped_key] = schema_in[key]
        if type(schema_in[key]) == dict:
            # Apply recursively.
            schema_out[stripped_key] = unprefix_schema_dict(schema_in[key])
    return schema_out


def get_boolean_input(question: str) -> bool:
    """Asks the given question and returns True if the user enters Y or False if they enter N"""
    while True:
        user_input = input(f"{question} [Y/n]:").lower()
        if user_input in ["y", "yes"]:
            return True
        elif user_input in ["n", "no"]:
            return False
        else:
            log.info("Please be sure to enter either 'yes' or 'no'")


def read_csv_file(file_path):
    """Reads csv a CSV file and return the parsed data as a list of list"""
    with open(file_path, "r") as csv_file:
        csv_data = list(csv.reader(csv_file))
    return csv_data


def strip_tba_team_key(team_key: str) -> str:
    """Removes `frc` from the beginning of tba team keys"""
    return team_key.replace("frc", "")


def get_teams_in_match(match: dict, alliance_color: str):
    if alliance_color not in ["red", "blue"]:
        raise ValueError("Alliance color has to be 'red' or 'blue'")
    return [strip_tba_team_key(key) for key in match["alliances"][alliance_color]["team_keys"]]


def near(float1: float, float2: float, dif=1e-9) -> bool:
    """Find if float1 is close to float2"""
    return isclose(float1, float2, rel_tol=dif, abs_tol=dif)


def dict_near(dict1: dict, dict2: dict, dif=1e-9) -> bool:
    """Find if dict1 is near to dict2, using the near function for floats and list_near for lists"""
    if len(dict1) != len(dict2):
        return False
    for field in dict1:
        if field not in dict2:
            return False
        if not (isinstance(dict1[field], float) and isinstance(dict2[field], float)):
            if isinstance(dict1[field], list):
                if not list_near(dict1[field], dict2[field], dif):
                    return False
            elif dict1[field] != dict2[field]:
                return False
        elif not near(dict1[field], dict2[field], dif):
            return False
    return True


def list_near(list1: list, list2: list, dif=1e-9) -> bool:
    """Find if list1 is near to list2, using near for floats"""
    if len(list1) != len(list2):
        return False
    for field1, field2 in zip(list1, list2):
        if not (isinstance(field1, float) and isinstance(field2, float)):
            if field1 != field2:
                return False
        elif not near(field1, field2, dif):
            return False
    return True


def dict_near_in(dict1: dict, list_of_dicts: List[dict], dif=1e-9) -> bool:
    """Find if dict1 is close to a dict inside list_of_dicts"""
    for dict2 in list_of_dicts:
        if dict_near(dict1, dict2, dif):
            return True
    return False


def find_dict_near_index(dict1: dict, list_of_dicts: List[dict], dif=1e-9) -> int:
    """Find the index of a dict close to dict1 in list_of_dicts"""
    for index, dict2 in enumerate(list_of_dicts):
        if dict_near(dict1, dict2, dif):
            return index
    raise ValueError


def near_in(float1: float, list_of_floats: list, dif=1e-9) -> bool:
    """Find if float1 is close to a float in list_of_floats"""
    for float2 in list_of_floats:
        if not (isinstance(float2, float) or isinstance(float2, int)):
            continue
        if near(float1, float2, dif):
            return True
    return False


def progress_bar(
    count: Union[int, float],
    total: Union[int, float],
    bar_len: int = 50,
) -> None:
    """Creates a progress bar in the terminal. To use this progress bar, call `progress_bar(currrent_count, total)` in a loop, incrementing the `current_count` from 1 to `total`.

    `count`: current count/progress

    `total`: total length (NOTE: `count` should increment from 1 to `total`

    `bar_len`: length of bar (characters)

    Prints the progress bar in the terminal. NOTE: you cannot print anything while the progress bar is running.
    """
    # Check if running under pytest
    if any("pytest" in arg for arg in sys.argv):
        return

    done = False

    # Calculate bar
    if count < total:
        filled_len = int(round(bar_len * (count - 1) / total))
        percent = round(100 * (count - 1) / total, 1)
        bar = "=" * filled_len + "-" * (bar_len - filled_len)
    # Completed
    elif count == total:
        bar = "=" * bar_len
        percent = 100.0
        done = True
    # Error occured; `count` > `total`
    else:
        return

    # Print bar
    sys.stdout.write(f"[{bar}] {percent}% ({count}/{total})\r")
    sys.stdout.flush()

    # Reset terminal
    if done:
        print()


def print(message="", color="cyan", **kwargs) -> None:
    """Prints a message to the terminal using coloring and formatting.

    `message`: message to print

    `color`: color of text, default "cyan" (do not change unless required)

    `kwargs`: extra arguments that can be passed to `console.print`
    """
    console.print(f"[{color}][bold]{message}", **kwargs)


def input(message="", color="cyan", **kwargs) -> str:
    """Prompts an input in the terminal using coloring and formatting.

    `message`: prompt to print

    `color`: color of prompt, default "cyan" (do not change unless required)

    `kwargs`: extra arguments that can be passed to `console.print`, formats the prompt

    Returns the recieved input from the user.
    """
    print(message, color, end="", **kwargs)
    return builtins.input()


def in_production() -> bool:
    "Returns True if `SCOUTING_SERVER_ENV='production'` and False otherwise."
    return True if os.environ.get("SCOUTING_SERVER_ENV") == "production" else False


def server_key() -> bool:
    "Returns database key (e.g. `test2024arc`)"
    with open("data/competition.txt") as f:
        return f"{'test' if not in_production() else ''}{f.read()}"


def confirm_comp(custom_message: str = None) -> None:
    """Prints the current competition key to the terminal, prompting the user to confirm the competition and production mode. If `SCOUTING_SERVER_ENV` is unset, the competition key will be displayed as `test<competition key>`.

    `custom_message`: if specified, you can print your own custom message to the terminal before asking the user for confirmation.
    """
    with open("data/competition.txt", "r") as f:
        competition = f"{'test' if not in_production() else ''}{f.read()}"
    if custom_message is None:
        custom_message = f"You are working with {competition=}. Is that right?"
    log.info(custom_message)

    while True:
        print("Hit enter to continue, or Ctrl-C to exit:")
        if input() == "":
            break


def get_server_path() -> str:
    return os.getcwd().split("server")[0] + "server/"


def has_internet() -> bool:
    try:
        subprocess.check_output(["ping", "-c", "1", "8.8.8.8"])
        return True
    except subprocess.CalledProcessError:
        return False


def unique_ld(ld: List[Dict]) -> List[Dict]:
    unique = []
    for item in ld:
        if item not in unique:
            unique.append(item)
    return unique


def get_team_list():
    with open(f"data/{TBA_EVENT_KEY}_team_list.json") as file:
        return json.load(file)


def get_match_schedule():
    with open(f"data/{TBA_EVENT_KEY}_match_schedule.json") as file:
        return json.load(file)


def write_ld_to_file(data: list[dict], file_path: str):
    "Writes specified list of dicts to either a JSON or CSV file."
    file_type = file_path.split(".")[-1]

    if file_type == "json":
        with open(file_path, "w") as f:
            f.write(json.dumps(data, indent=4))
    elif file_type == "csv":
        pd.DataFrame(data).to_csv(file_path, index=False)


def melt_data(data: dict[str, dict], key_name: str) -> list[dict]:
    "Melts data in the format `{a: {b: c, ...}, d: {e: f, ...}, ...}` into `[{z: a, b: c, ...}, {z: d, e: f, ...}]` where `z` is the `key_name`."
    melted_data = []

    for key, data in data.items():
        melted_data.append({key_name: key} | data)

    return melted_data


def extract_nested_dict(d, key_layers: list[str]) -> Any:
    "Extracts a value from a nested dictionary by navigating through `key_layers`"
    try:
        if len(key_layers) == 1:
            return d[key_layers[0]]
        else:
            return extract_nested_dict(d[key_layers[0]], key_layers[1:])
    except Exception as err:
        log.error(f"Unable to extract {key_layers}: {err}")
        return None


def modes(data: list) -> list:
    """Returns the most frequently occurring items in the given list"""
    if len(data) == 0:
        return []
    # Create a dictionary of things to how many times they occur in the list
    frequencies = {}
    for item in data:
        frequencies[item] = 1 + frequencies.get(item, 0)
    # How many times each mode occurs in nums:
    max_occurrences = max(frequencies.values())
    return [item for item, frequency in frequencies.items() if frequency == max_occurrences]


def prettyprint(obj) -> None:
    pprint.pp(obj, indent=4)


def read_ld_from_file(file_path: str) -> list[dict]:
    data = []
    file_type = file_path.split(".")[-1]

    if file_type == "json":
        with open(file_path) as f:
            return json.load(f)
    elif file_type == "csv":
        with open(file_path) as f:
            csvreader = csv.reader(f)
            header = next(csvreader)
            indexes = {var: header.index(var) for var in header}

            for row in csvreader:
                row_doc = dict()
                for key, i in indexes.items():
                    row_doc[key] = row[i]
                data.append(row_doc)
    else:
        log.warning(f"Invalid read file type '{file_type}'")

    return data


# This exact function is also defined in decompressor.py, but it's here because importing decompressor in some files is awkward due to circular import errors
def get_qr_identifiers(qr) -> dict:
    "Extracts the match number, scout name, team number, scout ID, and alliance team list from a raw QR. If datapoint does not exist (for example subjective QRs have no scout ID), the dict value is `None`."
    # TODO un-hardcode this to use the character codes in match_collection_qr_schema
    # Currently, it's using the positions of character codes withint the QR, which is fine until the orders are changed in schema
    data = {
        "is_obj": qr[0] == "+",
        "match_number": None,
        "scout_name": None,
        "team_number": None,
        "scout_id": None,
        "aim_team_list": None,
    }

    try:
        generic_data = qr.split("%")[0].split("$")
        data["match_number"] = int(generic_data[1][1:])
        data["scout_name"] = generic_data[4][1:]
        if data["is_obj"]:
            tim_data = qr.split("%")[1].split("$")
            data["team_number"] = tim_data[0][1:]
            data["scout_id"] = tim_data[1][1:]
        else:
            data["aim_team_list"] = list(
                map(
                    lambda section: section.split("$")[0][1:],
                    qr.split("%")[1].split("#"),
                )
            )
    except Exception as err:
        log.error(f"Invalid QR '{qr}', cannot extract data: {err}")

    return data


def calc_weighted_sum(data: dict, weights: dict) -> Union[int, float]:
    val = 0

    for var, weight in weights.items():
        try:
            val += data[var] * weight
        except Exception as err:
            log.error(f"Cannot find {var=} when calculating weighted sum")

    return val


def create_abs_path(local_path: str) -> str:
    "Turns the given local path to server/ to an absolute path (e.g. data/data_status.txt becomes /home/user/server/data/data_status.txt)"
    utils_path = list(Path(__file__).parts)
    server_path = Path(*utils_path[: utils_path.index("server") + 1])

    return (server_path / local_path).resolve()


def knit_ipynb(ipynb_path: str, out_path: str) -> None:
    run_command(
        f"jupyter nbconvert --to {out_path.split('.')[-1]} --no-input --output {create_abs_path(out_path)} {create_abs_path(ipynb_path)}"
    )


def type_cast(datapoint, str_type):
    str_to_type = {
        "str": str,
        "int": int,
        "float": float,
        "bool": bool,
        "dict": dict,
        "list": list,
        "set": set,
        "tuple": tuple,
    }
    return str_to_type[str_type](datapoint)


_TBA_EVENT_KEY_FILE = "data/competition.txt"
TBA_EVENT_KEY = load_tba_event_key_file(_TBA_EVENT_KEY_FILE)

if sys.prefix == sys.base_prefix:
    log.info("Hey friend! Don't forget to activate the virtual environment")
